{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-processed data bundle - javadoc for train set, android for test set\n",
    "data = LanguagePairDataset('bundle', use_cuda=torch.cuda.is_available(),\n",
    "                           src_maxlen=300, dst_maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load extraction results from our approach as the test set\n",
    "test_label = np.array([int(line.strip())\n",
    "                       for line in open('results.txt')])\n",
    "test_train = np.random.rand(len(data.test)) > 0.3\n",
    "test_holdout = np.zeros(len(data.test), np.bool)\n",
    "for i in range(0, 90000, 300):\n",
    "    test_holdout[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size and number of dimensions\n",
    "bs = 100\n",
    "nd = 300\n",
    "\n",
    "# parameter grid for two options: model architecture and training dataset\n",
    "grid = dict(\n",
    "    model = [\n",
    "        lambda: Matcher(\n",
    "            Encoder(len(data.src_vocab), nd),\n",
    "            Encoder(len(data.dst_vocab), nd),\n",
    "            n_enc = nd,\n",
    "            n_hid = nd,\n",
    "        ),\n",
    "        lambda: Seq2Seq(\n",
    "            Encoder(len(data.src_vocab), nd),\n",
    "            Encoder(len(data.dst_vocab), nd),\n",
    "        )\n",
    "    ],\n",
    "    trainset = [\n",
    "        ('javadoc', data.train, data.test),\n",
    "        ('label1_test',\n",
    "             data.test[(test_label == 1) & (~test_holdout)],\n",
    "             data.test[test_holdout],\n",
    "        ),\n",
    "        ('random_test',\n",
    "             data.test[test_train & (~test_holdout)],\n",
    "             data.test[test_holdout],\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training options: starting and ending epoch\n",
    "# start from a positive number to resume previous training\n",
    "n_epoch_start = 0\n",
    "n_epoch_end = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (model_gen, (trainset_name, trainset, testset)) in enumerate(itertools.product(*grid.values())):\n",
    "    model = model_gen()\n",
    "    if data.use_cuda:\n",
    "        model.cuda()\n",
    "    model_name =  f'Model_{model.__class__.__name__}-trainset_{trainset_name}'\n",
    "    print('=' * 80)\n",
    "    print(i + 1, model_name)\n",
    "    print('=' * 80)\n",
    "    for name, dataset in [('train', trainset), ('test', testset)]:\n",
    "        x, y, m = data.batch(np.random.choice(dataset, bs))\n",
    "        print('-' * 20, 'sample', name, 'data', '-' * 20)\n",
    "        print('>> src')\n",
    "        pprint(data.src_vocab, x[0])\n",
    "        print('>> dst')\n",
    "        pprint(data.dst_vocab, y[0])\n",
    "        print()\n",
    "    print('train/test size', len(trainset), len(testset))\n",
    "    for epoch in range(n_epoch_start, n_epoch_end):\n",
    "        print()\n",
    "        print('Epoch', epoch + 1, flush=True)\n",
    "        fname = f'checkpoints/{model_name}-epoch_{epoch + 1}'\n",
    "        if os.path.isfile(fname):\n",
    "            model = torch.load(fname, map_location='cuda' if data.use_cuda else 'cpu')\n",
    "            continue\n",
    "        # train\n",
    "        optim = torch.optim.Adam(model.parameters())\n",
    "        model.train()\n",
    "        if isinstance(model, Matcher):\n",
    "            data.negative_sample = 0.5\n",
    "        else:\n",
    "            data.negative_sample = 0\n",
    "        data.one_epoch(model, shuffled(trainset), bs, optim=optim)\n",
    "        torch.save(model, fname)\n",
    "        # eval\n",
    "        model.eval()\n",
    "        if isinstance(model, Matcher):\n",
    "            idx = data.test[test_holdout]\n",
    "            x, y, m = data.batch(idx)\n",
    "            if data.use_cuda():\n",
    "                x = x.cuda()\n",
    "            y_ = model.forward(x)\n",
    "            s = roc_auc_score(y.cpu().numpy(), y_.cpu().numpy())\n",
    "            print('roc_auc_score', s)\n",
    "        else:\n",
    "            idx = data.test[test_holdout][test_label[test_holdout]==1]\n",
    "            x, y, m = data.batch(idx)\n",
    "            if data.use_cuda:\n",
    "                x = x.cuda()\n",
    "            y_ = model.translate(x, data.dst_maxlen)\n",
    "            s = np.mean([bleu(y[i], y_[i]) for i in range(bs)])\n",
    "            print('bleu score', s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
